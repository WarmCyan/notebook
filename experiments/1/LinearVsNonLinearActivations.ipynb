{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Linear vs Non-Linear Activations in Neural Networks\n",
    "\n",
    "(Initially started 7/8/2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Prior, I've had misconceptions about how activation functions affect how a neural network works. Largely, I felt that it would make sense to use \"linear neural networks\" for learning something like a math formula. (A more linear-regression type problem?) The only context where I had explicitly thought about activation functions in a non-linear neural network, I apparently assumed them to always be sigmoidal, like many examples online! I have since discovered ReLU's are a thing, and at least vaguely understand the limitations of a linear neural network as compared to a non-linear neural network <span style='color: red'>[TODO: Prove this or find citation?]</span> but I'm continuing this experiment to see how different activations compare for different problem types.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something I've wanted to test for a while, I'm very curious how well neural networks will be able to learn and generalize simple math formulas. It seems like this is something that would be very easy for the networks to do (based on activation function?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do different activation functions like ReLU and logistic compare on different types of problems such as regression versus classification? How do they compare to purely linear neural networks? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nbhelper as nb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some different types of activation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACFCAYAAACAJLCMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nueQLHl4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5770e665c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb.plot_identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identity** - This is just a linear activation. A neural network that uses only identity activation functions is a linear neural network. Interestingly, regardless of how many layers a linear neural network has, it's functionally equivalent to a single layer neural network (making it a glorified affine transformation) [2]. <span style='color: red'>[TODO: prove this?]</span>\n",
    "\n",
    "It has a simple formula:\n",
    "$$\n",
    "f(x)=x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACFCAYAAACAJLCMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f576c131630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb.plot_relu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReLU** - Rectified Linear Unit. This is essentially just the identity activation function, but it introduces non-linearity by zeroing anything less than $x=0$. This (to me) seems especially powerful in terms of still appropriately being able to handle regression problems, while still allowing for the greater complexity a non-linear multi-layer network can provide? ReLU's are one of the most popular activation networks in deep neural networks [3].\n",
    "\n",
    "Similarly simple formula: \n",
    "$$\n",
    "f(x)=\\textrm{max}(0,x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIUAAACFCAYAAAB12js8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4JzQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f576e166cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb.plot_logistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic** - The logistic function is a sigmoid (s-curve) that seems to be frequently used as the activation function in neural network tutorials due to it's trivially simple derivative [5]:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "$$\n",
    "\\frac{d}{dx}f(x) = f(x)(1-f(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACFCAYAAACAJLCMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS/4P0dBXf5OLtdMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f576c04b5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb.plot_tanh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperbolic Tangent** - The hyperbolic tangent, or $tanh$, is similar in shape to the logistic, but has a range of -1 to 1, rather than 0 to 1.\n",
    "\n",
    "It's formula is [6]:\n",
    "$$\n",
    "f(x) = tanh x = \\frac{1-e^{-2x}}{1+e^{-2x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment will consist of a set of different problems, and for each problem, I'll run a network for several different architectures for several different activation function types:\n",
    "\n",
    "**Architectures:**\n",
    "<span style='color: red'>[TODO: TBD]</span>\n",
    "\n",
    "**Activation Functions:**\n",
    "- Identity (linear)\n",
    "- ReLU\n",
    "- Logistic\n",
    "- TanH\n",
    "\n",
    "**Problems:**\n",
    "- Generated addition data, learn the formula $f(i_1,i_2)=i_1+i_2$\n",
    "- Generated exponential data, learn the formula $f(i_1,i_2)={i_1}^{i_2}$ <span style='color: purple'>This seems like it'd be pretty difficult to learn, since calculating this requires looping? Very curious how this turns out</span>\n",
    "- Generated addition data, but inputs represented in binary\n",
    "- Generated exponential data, but inputs represented in binary\n",
    "- Generated classification data for if input point is within circle: \n",
    "$\n",
    "f(i_1,i_2,h,k,r) = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "            1 & : (x-h)^2 + (y-k)^2 \\leq r^2 \\\\\n",
    "            0 & : (x-h)^2 + (y-k)^2 > r^2\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$\n",
    "- Generated quadratic formula data: $f(a,b,c)=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}$\n",
    "<span style='color: purple'>For now, all imaginary solutions will be ignored</span>\n",
    "\n",
    "**Data Collection:**\n",
    "- Architecture\n",
    "- Activation function\n",
    "- Training data row count\n",
    "- Problem domain sizes\n",
    "- Epoch count\n",
    "- Training time\n",
    "- (Regression) Mean squared error [4]\n",
    "- (Binary classification) Confusion matrix stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color: purple'>NOTES</span>\n",
    "\n",
    "Read: [http://journal.frontiersin.org/article/10.3389/fncom.2014.00043/full](http://journal.frontiersin.org/article/10.3389/fncom.2014.00043/full) for more info on metrics etc. (Mostly only discusses different ways of using confusion matrix metrics)\n",
    "\n",
    "Also, an interesting thing to include in the testing datasets for regression problems would be something farther in range (so for addition, a far larger addition problem than normal) than it ever saw in training to check if it's actually generalized well enough or not. <span style='color: red'>[Any sources of something like this being done?]</style>\n",
    "\n",
    "Something to explore later is why something simple like an XOR network seems to require two outputs (like a classifier) as opposed to being able to output the result to one output neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "[1] [https://en.wikipedia.org/wiki/Activation_function](https://en.wikipedia.org/wiki/Activation_function)  \n",
    "[2] [http://people.whitman.edu/~hundledr/courses/M350S08/Ch10.pdf](http://people.whitman.edu/~hundledr/courses/M350S08/Ch10.pdf)  \n",
    "[3] [https://en.wikipedia.org/wiki/Rectifier_(neural_networks)](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))  \n",
    "[4] [https://en.wikipedia.org/wiki/Mean_squared_error](https://en.wikipedia.org/wiki/Mean_squared_error)  \n",
    "[5] [https://en.wikipedia.org/wiki/Logistic_function](https://en.wikipedia.org/wiki/Logistic_function)  \n",
    "[6] [https://en.wikipedia.org/wiki/Hyperbolic_function#Hyperbolic_tangent](https://en.wikipedia.org/wiki/Hyperbolic_function#Hyperbolic_tangent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
